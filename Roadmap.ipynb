{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Roadmap</h1>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li style=\"color:green\">Explore a website, create and test separate parsing scripts for different levels of parsing.</li>\n",
    "    <li style=\"color:green\">Create parsing_module.py containing parsing functions</li>\n",
    "    <li style=\"color:green\">Define parsing schema</li>\n",
    "    <li>Define the structure of a database</li>\n",
    "    <li>Set up the database on a machine</li>\n",
    "    <li>Parse all product links</li>\n",
    "    <li>Parse each product page</li>\n",
    "    <li>Create API for data access</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define Parsing Schema</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I would like to parse all product links in the first parsing stage and then use this links to parse product info on the second stage.</p>\n",
    "<img src=\"screenshots/parsed_dataframe.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The website contais <b>1224</b> subcategory_lvl_2, each subcategory has a link to its products page. I've already made a script that extracts all product links from single subcategory_lvl_2. Each subcetgory_lvl_2 contains about <b>62</b> products which results in <b>75 000 products </b> in catalog in total.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It seems like a good idea to parse 75 000 product links in the first place because this will enable quality parsing of separate products on the second stage. Especially considering the fact that we have to extract and store similar products.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define Database Structure</h3>\n",
    "<p>I've discovered that tree-like database sctructure seems like the best choice for our case.</p>\n",
    "<img src=\"screenshots/tree_schematic.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>From https://kite.com/blog/python/sqlalchemy :</p>\n",
    "<p>There are a variety of well-known approaches for storing trees in a relational database. A common technique is using the <i><b>materialized path pattern</b></i>, in which each node keeps a record of the path to reach it from the root of the tree. This approach allows for fast inserts and fast queries, but moving an existing node to a different tree can be slow and expensive, as you have to rewrite the paths on any descendants of that node. </p>\n",
    "<p>If you happen to be using Postgres as your database – you’re in luck! Postgres actually offers a custom data type called <i><b>LTree</i></b> specifically designed to record materialized paths for representing trees.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
