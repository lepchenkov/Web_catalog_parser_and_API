{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Roadmap</h1>\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li style=\"color:green\">Explore a website, create and test separate parsing scripts for different levels of parsing.</li>\n",
    "    <li style=\"color:green\">Create parsing_module.py containing parsing functions</li>\n",
    "    <li style=\"color:green\">Define parsing schema</li>\n",
    "    <li style=\"color:green\">Define the structure of a database</li>\n",
    "    <li style=\"color:green\">Set up the database on a machine</li>\n",
    "    <li style=\"color:green\">Parse all product links into Postgres db</li>\n",
    "    <li style=\"color:green\">Extend product_links_table to accomodate product data (add celery to create parsing intervals)</li>\n",
    "    <li style=\"color:orange\">Parse each product page into db</li>\n",
    "    <li>Create API for data access</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define Parsing Schema</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I would like to parse all product links in the first parsing stage and then use this links to parse product info on the second stage.</p>\n",
    "<img src=\"screenshots/parsed_dataframe.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The website contais <b>1224</b> subcategory_lvl_2, each subcategory has a link to its products page. I've already made a script that extracts all product links from single subcategory_lvl_2. The shop claims to have about <b>75 000 products </b> in catalog in total.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It seems like a good idea to parse 75 000 product links in the first place because this will enable quality parsing of separate products on the second stage. Especially considering the fact that we have to extract and store similar products.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define Database Structure</h3>\n",
    "<p>I've discovered that tree-like database sctructure seems like the best choice for our case.</p>\n",
    "<img src=\"screenshots/tree_schematic.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>From https://kite.com/blog/python/sqlalchemy :</p>\n",
    "<p>There are a variety of well-known approaches for storing trees in a relational database. A common technique is using the <i><b>materialized path pattern</b></i>, in which each node keeps a record of the path to reach it from the root of the tree. This approach allows for fast inserts and fast queries, but moving an existing node to a different tree can be slow and expensive, as you have to rewrite the paths on any descendants of that node. </p>\n",
    "<p>If you happen to be using Postgres as your database – you’re in luck! Postgres actually offers a custom data type called <i><b>LTree</i></b> specifically designed to record materialized paths for representing trees.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Use intermediate table?</h3>\n",
    "<p>I have collected all product links intor single table in postgres db. The table contains <b>24092 entries</b> and has following columns:</p>\n",
    "<ul>\n",
    "    <li>id</li>\n",
    "    <li>url</li>\n",
    "    <li>category</li>\n",
    "    <li>subcat_lvl1</li>\n",
    "    <li>subcat_lvl2</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"screenshots/parsed_table.png\" align=\"left\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Implementing tree-based database does not seem completely transparent. So it seems like a good idea to extend an existing table with product attributes and the parse each product into this table.</p>\n",
    "<ul>\n",
    "    <li>product_name <i>VARCHAR</i></li>\n",
    "    <li>product_price <i>NUMERIC (5, 2)</i></li>\n",
    "    <li>product_description <i>VARCHAR</i></li>\n",
    "    <li>product_characteristics <i>VARCHAR</i></li>\n",
    "    <li style=\"color:red\">similar_products <b>(could not get similar products (ajax call))</b> <i>VARCHAR for now</i></li>\n",
    "    <li>product_image_link <i>VARCHAR</i></li>\n",
    "    <li>product_is_hit <i>BOOLEAN</i></li>\n",
    "    <li>is_parsed <i>TIMESTAMP</i></li>\n",
    "</ul>\n",
    "\n",
    "<p>Getting similar products out of plane html does not seem possible, so i will leave similar column empty for now and fill the intermediate table with product information.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extend existing product links table</h3>\n",
    "<p>I have extended existing table with new columns according to task requirements</p>\n",
    "\n",
    "<img src=\"screenshots/product_table.png\" align=\"left\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>What's next:</h3>\n",
    "<p>1. Iterate over product links and collect product data from each page using get_product_parameters function in parsing_module.py. </p>\n",
    "<p>2. When parsing is done: create tree-type database out of single preliminary denormalized table. </p>\n",
    "<p>3. Create API for access. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exectution time estimation</h3>\n",
    "<p>I've tried to parse 300 product pages and it too 4 minutes 51 secods. So without adding multiprocessing the whole process of parsing each product entry will take about 6,5 hours.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Collect product data into extended products_all table</h3>\n",
    "<p>I've tried to parse 500 product pages and it took 8 minutes 46 secods. So without adding multiprocessing the whole process of parsing each product entry will take about 6,5 hours.</p>\n",
    "<img src=\"screenshots/parse_product_info_into_extended_db.png\" align=\"left\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I've also tested retrieving parsed product data from db by id.</p>\n",
    "<img src=\"screenshots/parsed_product.png\" align=\"left\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
